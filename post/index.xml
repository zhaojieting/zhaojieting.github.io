<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Latest News | Robot Vision and Navigation Lab</title>
    <link>https://robot-vision-and-navigation-lab.github.io/post/</link>
      <atom:link href="https://robot-vision-and-navigation-lab.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Latest News</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 05 May 2022 23:31:05 +0800</lastBuildDate>
    <image>
      <url>https://robot-vision-and-navigation-lab.github.io/media/icon_hufd23fe07f913647ae034fd53d5c713c2_6850_512x512_fill_lanczos_center_3.png</url>
      <title>Latest News</title>
      <link>https://robot-vision-and-navigation-lab.github.io/post/</link>
    </image>
    
    <item>
      <title>A New CVPR Article</title>
      <link>https://robot-vision-and-navigation-lab.github.io/post/test_news_3/</link>
      <pubDate>Thu, 05 May 2022 23:31:05 +0800</pubDate>
      <guid>https://robot-vision-and-navigation-lab.github.io/post/test_news_3/</guid>
      <description>&lt;h2 id=&#34;hahahugoshortcode-s0-hbhb&#34;&gt;&lt;div class=&#34;ratio ratio-16x9 bilibili&#34;&gt;
  &lt;iframe
    src=&#34;https://player.bilibili.com/player.html?bvid=BV1Ka411q72H&#34;
    width=&#34;100%&#34; height=&#34;400px&#34;
    scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34;
    loading=&#34;lazy&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;Monocular person following (MPF) is a capability that supports many useful applications of a mobile robot. However, existing MPF solutions are not completely satisfactory. Firstly, they often fail to track the target at a close distance either because they are based on visual servo or they need the observation of the full body by the robot. Secondly, their target Re-IDentiﬁcation (Re-ID) abilities are weak in cases of target appearance change and highly similar appearance of distracting people. To remove the assumption of full-body observation, we propose a width-based tracking module, which relies on the target width, which can be observed even at a close distance. For handling issues related to appearance variation, we use a global CNN (convolutional neural network) descriptor to represent the target and a ridge regression model to learn a target appearance model online. We adopt a sampling strategy for online classiﬁer learning, in which both long-term and short-term samples are involved. We evaluate our method in two datasets including a public person following dataset and a custom-built with challenging target appearance and target distance. Our method achieves state-of-the-art (SOTA) results on both datasets. The code and dataset of our work in this research are publicly available in &lt;a href=&#34;https://github.com/MedlarTea/MPF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/MedlarTea/MPF&lt;/a&gt; GRR SLT.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A New ICRA Article</title>
      <link>https://robot-vision-and-navigation-lab.github.io/post/test_news_2/</link>
      <pubDate>Thu, 05 May 2022 23:31:05 +0800</pubDate>
      <guid>https://robot-vision-and-navigation-lab.github.io/post/test_news_2/</guid>
      <description>&lt;h2 id=&#34;hahahugoshortcode-s0-hbhb&#34;&gt;&lt;div class=&#34;ratio ratio-16x9 bilibili&#34;&gt;
  &lt;iframe
    src=&#34;https://player.bilibili.com/player.html?bvid=BV1Ka411q72H&#34;
    width=&#34;100%&#34; height=&#34;400px&#34;
    scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34;
    loading=&#34;lazy&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;Monocular person following (MPF) is a capability that supports many useful applications of a mobile robot. However, existing MPF solutions are not completely satisfactory. Firstly, they often fail to track the target at a close distance either because they are based on visual servo or they need the observation of the full body by the robot. Secondly, their target Re-IDentiﬁcation (Re-ID) abilities are weak in cases of target appearance change and highly similar appearance of distracting people. To remove the assumption of full-body observation, we propose a width-based tracking module, which relies on the target width, which can be observed even at a close distance. For handling issues related to appearance variation, we use a global CNN (convolutional neural network) descriptor to represent the target and a ridge regression model to learn a target appearance model online. We adopt a sampling strategy for online classiﬁer learning, in which both long-term and short-term samples are involved. We evaluate our method in two datasets including a public person following dataset and a custom-built with challenging target appearance and target distance. Our method achieves state-of-the-art (SOTA) results on both datasets. The code and dataset of our work in this research are publicly available in &lt;a href=&#34;https://github.com/MedlarTea/MPF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/MedlarTea/MPF&lt;/a&gt; GRR SLT.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A New IROS Article</title>
      <link>https://robot-vision-and-navigation-lab.github.io/post/test_news/</link>
      <pubDate>Thu, 05 May 2022 23:31:05 +0800</pubDate>
      <guid>https://robot-vision-and-navigation-lab.github.io/post/test_news/</guid>
      <description>&lt;h2 id=&#34;hahahugoshortcode-s0-hbhb&#34;&gt;&lt;div class=&#34;ratio ratio-16x9 bilibili&#34;&gt;
  &lt;iframe
    src=&#34;https://player.bilibili.com/player.html?bvid=BV1Ka411q72H&#34;
    width=&#34;100%&#34; height=&#34;400px&#34;
    scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34;
    loading=&#34;lazy&#34;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;Monocular person following (MPF) is a capability that supports many useful applications of a mobile robot. However, existing MPF solutions are not completely satisfactory. Firstly, they often fail to track the target at a close distance either because they are based on visual servo or they need the observation of the full body by the robot. Secondly, their target Re-IDentiﬁcation (Re-ID) abilities are weak in cases of target appearance change and highly similar appearance of distracting people. To remove the assumption of full-body observation, we propose a width-based tracking module, which relies on the target width, which can be observed even at a close distance. For handling issues related to appearance variation, we use a global CNN (convolutional neural network) descriptor to represent the target and a ridge regression model to learn a target appearance model online. We adopt a sampling strategy for online classiﬁer learning, in which both long-term and short-term samples are involved. We evaluate our method in two datasets including a public person following dataset and a custom-built with challenging target appearance and target distance. Our method achieves state-of-the-art (SOTA) results on both datasets. The code and dataset of our work in this research are publicly available in &lt;a href=&#34;https://github.com/MedlarTea/MPF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/MedlarTea/MPF&lt;/a&gt; GRR SLT.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
